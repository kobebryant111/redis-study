## redis学习

### 1.探索「字符串」内部结构---底层

Redis 的字符串叫「SDS」，也就是 Simple Dynamic String。它的结构是一个带长度信息的字节数组。(因为redis不方便计算字符串的长度)

```java
struct SDS {
 T capacity; // 数组容量,数据容量一般大于数组长度
 T len; // 数组长度
 byte flags; // 特殊标识位，不理睬它
 byte[] content; // 数组内容
}
```

```java
Redis 对象头结构体，所有的redis对象都有这个头结构体
struct RedisObject {
 int4 type; // 4bits
 int4 encoding; // 4bits
 int24 lru; // 24bits 最后访问的时间戳，用于LRU算法
 int32 refcount; // 4bytes
 void *ptr; // 8bytes，64-bit system
} robj;
```

意味着分配一个字符串（不算字符串本身）的最小空间占用为 19 字节（16+3）。

embstr 存储形式是这样一种存储形式，它将 RedisObject 对象头和 SDS 对
象连续存在一起，使用 malloc 方法一次分配。而 raw 存储形式不一样，它需要两次malloc，两个对象头在内存地址上一般是不连续的。

留给 content 的长度最多只有 45(64-19) 字节了。字符串又是以\0 结尾，所以 embstr 最大能容纳的字符串长度就是 44。字符串长度超过44就是raw方式。



### 2.redis分布式锁---应用

占坑一般是使用 setnx(set if not exists) 指令，只允许被一个客户端占坑。先来先占， 用完了，再调用 del 指令释放茅坑。

set lock:codehole true ex 5 nx 这条指令。使得 setnx 和expire 指令可以一起执行，彻底解决了分布式锁的乱象。**简而言之就是抢夺锁并且给锁设置一个过期时间**。

当然具体在代码中的使用还待思考。



### 3.redis基础数据结构---底层

- String：除了一般的key-value，还可以存储对象信息。我们将用户信息结构体使用 JSON 序列化成字符串，然后将序列化后的字符串塞进 Redis 来缓存。同样，取用户信息会经过一次反序列化的过程。 

  eg: set name codehole 

- hash：一般用于存储对象信息。hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡。

   eg: hset books java "think in java" 

- list：Redis 的list结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。

  eg: rpush books python java golang

- set：set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。

   eg: sadd books python 

- zset：zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。

   eg: zadd books 9.0 "think in java" 




### 4.延时队列---应用

Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列，使用 lpop 和 rpop 来出队列。

Redis 的消息队列不是专业的消息队列，它没有非常多的高级特性，没有 ack 保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用。（那这一点不是直接就pass了啊，下一节下一节）。



### 5.位图---应用

Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下，这就大大节约了存储空间。

**其实并不是特殊的数据结构，就是String类型**。Redis 提供了位图统计指令bitcount 和位图查找指令 bitpos，bitcount 用来统计指定位置范围内 1 的个数，bitpos 用来查找指定范围内出现的第一个 0 或 1。

 eg: setbit s 1 1 



### 6.线程 IO 模型---原理

Redis是单线程，如何处理那么多的并发客户端连接？多路复用

有了非阻塞 IO 意味着线程在读写 IO 时可以不必再阻塞了，读写可以瞬间完成然后线程可以继续干别的事了。（意思就是一个客户端处理的速度非常快）

Redis 会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。Redis 同样也会为每个客户端套接字关联一个响应队列。Redis 服务器通过响应队列来将指令的返回结果回复给客户端。 



### 7.通信协议---原理

RESP 是 Redis 序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。**简而言之就是客户端与redis服务器之间的数据与指令传递的格式**。

**客户端 -> 服务器**   客户端向服务器发送的指令只有一种格式---多行字符串数组。set author codehole 会被序列化成下面的字符串。

*3\r\n$3\r\nset\r\n$6\r\nauthor\r\n$8\r\ncodehole\r\n



### 8.持久化---原理

Redis 的数据全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。

Redis 的持久化机制有两种，第一种是快照，第二种是 AOF 日志。

- **快照**：在服务线上请求的同时，Redis 还需要进行内存快照，内存快照要求 Redis 必须进行文件 IO 操作，可文件 IO 操作是不能使用多路复用 API(可以理解为在边于各个客户端交互时，同时又要边进行快照)。Redis 使用**操作系统的多进程 COW(Copy On Write) 机制**来实现快照持久化，这个机制很有意思，也很少人知道。多进程 COW 也是鉴定程序员知识广度的一个重要指标。
- **AOF**：就是将操作日志指令（什么get,set）存储下来，然后再顺序执行指令，那么所有的数据都又有了。Redis 会在收到客户端修改指令后，先进行参数校验，如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是先存到磁盘，然后再执行指令。这样即使遇到突发宕机，已经存储到 AOF 日志的指令进行重放一下就可以恢复到宕机前的状态。
- AOF重写：Redis 在长期运行的过程中，AOF 的日志会越变越长。此时重新遍历一遍redis数据，然后看看使用多少指令能够一下子就还原数据。然后就把这些指令存储到新的AOF日志。



### 9.stream---拓展

Redis5.0 最大的新特性就是多出了一个数据结构 Stream，它是一个新的强大的支持多播的可持久化的消息队列，作者坦言 Redis Stream 狠狠地借鉴了 Kafka 的设计。

消息队列具体的就先不看了，rocketMQ还没整明白呢。感觉Stream不具有啥优势相比于主流的消息队列。



### 10.Info 指令---拓展

在使用 Redis 时，时常会遇到很多问题需要诊断，在诊断之前需要了解 Redis 的运行状态，通过强大的 Info 指令，你可以清晰地知道 Redis 内部一系列运行参数。

- Redis每秒执行多少条指令**info stats**。下图客户端每秒会发送 789 条指令到服务器执行。极限情况下，Redis 可以秒执行 10w 次指令，CPU 几乎完全榨干。在这时我们可以考虑通过 **monitor** 指令快速观察一下究竟是哪些 key 访问比较频繁，从而在相应的业务上进行优化，以减少 IO 次数。

  ```redis
  # ops_per_sec: operations per second，也就是每秒操作数
  > redis-cli info stats |grep ops
  instantaneous_ops_per_sec:789
  ```


- Redis连接了多少客户端**info clients**。可以使用 **client list** 指令列出所有的客户端链接地址来确定源头。**rejected_connections**表示因为超出最大连接数限制而被拒绝的客户端连接次数。

- Redis内存占多大**info memory**。

  ```redis
  > redis-cli info memory | grep used | grep human
  used_memory_human:827.46K # 内存分配器 (jemalloc) 从操作系统分配的内存总量
  used_memory_rss_human:3.61M # 操作系统看到的内存占用 ,top 命令看到的内存
  used_memory_peak_human:829.41K # Redis 内存消耗的峰值
  used_memory_lua_human:37.00K # lua 脚本引擎占用的内存大小
  ```


- 复制积压缓冲区多大？**info replication**



### 11.主从同步---原理

很多企业都没有使用到 Redis 的集群，但是至少都做了主从。有了主从，当 master 挂掉的时候，运维让从库过来接管，服务就可以继续，否则 master 需要经过数据恢复和重启的过程，这就可能会拖很长的时间，影响线上业务的持续服务。（意思就是搞了个后备库防止突发情况）。

**CAP 原理**就好比分布式领域的牛顿定律，它是分布式存储的理论基石（太牛逼了）。一句话概括 CAP 原理就是——网络分区发生时（可以理解为网络断开），数据的一致性和可用性两难全。牺牲可用性是指是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。

Redis 的主从数据是异步同步的。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致。（这个备胎要一直不停地模仿主节点，渴望有上场机会 ）。

当从节点刚刚加入到集群时，它必须先要进行一次**快照同步**，同步完成后再继续进行**增量同步**。(这两个同步可以深入了解一下)

我觉得主从同步的难点就是实时性，很难解决。主从复制是 Redis 分布式的基础，Redis 的高可用离开了主从复制将无从进行。如果用redis只是想要做缓存，那么没必要主从同步。但是如果使用了 Redis 的持久化功能（就是直接存数据在redis中），就必须认真对待主从复制，它是系统数据安全的基础保障。



### 12. 集群 1：李代桃僵 —— Sentinel

主从同步需要运维人员手工进行从主切换，再通知所有的程序把地址统统改一遍重新上线（这确实有点麻烦）。所以我们现在需要一个东西能够自动进行从主切换，程序可以不用重启，运维可以继续睡大觉，仿佛什么事也没发生一样（这样确实舒服啊）。

Redis Sentinel 集群负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接集群时，会首先连接sentinel，通过 sentinel 来查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户端。如此应用程序将无需重启即可自动完成节点切换。

具体怎么实现的可以具体再研究一下。



### 13. 集群 2：分而治之 —— Codis

在大数据高并发的需求之下，Redis 集群方案应运而生。它可以将众多小内存的 Redis 实例综合起来，将分布在多台机器上的众多 CPU 核心的计算能力聚集到一起，完成海量数据存储和高并发读写操作。

Codis 是 Redis 集群方案之一，令我们感到骄傲的是，它是中国人开发并开源的，来自前豌豆荚中间件团队。

当客户端向 Codis 发送指令时，Codis 负责将指令转发到后面的 Redis 实例
来执行，并将返回结果再转回给客户端。



### 14.集群 3：众志成城 —— Cluster

RedisCluster 是 Redis 的亲儿子，它是 Redis 作者自己提供的 Redis 集群化方案。

Redis Cluster 将所有数据划分为 16384 的 槽位，它比 Codis 的 1024 个槽划分的更为精细，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中，它不像 Codis，它不需要另外的分布式存储来存储节点槽位信息。当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息。这样当客户端要查找某个 key 时，可以直接定位到目标节点。

Redis Cluster 可以为每个主节点设置若干个从节点，单主节点故障时，集群会自动将其中某个从节点提升为主节点。如果某个主节点没有从节点，那么当它发生故障时，集群将完全处于不可用状态。

具体的很多Cluster知识以及原理还没有搞懂，还需要冷静下来好好分析。



### 15.再看Redis分布式锁---拓展

在集群环境下，上面讲到的分布式锁是有缺陷的，它不是绝对安全的。

比如在 Sentinel 集群中，主节点挂掉时，从节点会取而代之，客户端上却并没有明显感知。原先第一个客户端在主节点中申请成功了一把锁，但是这把锁还没有来得及同步到从节点，主节点突然挂掉了。然后从节点变成了主节点，这个新的节点内部没有这个锁，所以当另一个客户端过来请求加锁时，立即就批准了。这样就会导致系统中同样一把锁被两个客户端同时持有，不安全性由此产生。

为了解决这个“不大不小”的问题，需要使用Redlock 算法。加锁时，它会向过半节点发送 set(key, value, nx=True, ex=xxx) 指令，只要过半节点 set成功，那就认为加锁成功。释放锁时，需要向所有节点发送 del 指令。

如果你很在乎高可用性，希望挂了一台 redis 完全不受影响，那就应该考虑 redlock。不过代价也是有的，需要更多的 redis 实例，性能也下降了，代码上还需要引入额外的library，运维上也需要特殊对待，这些都是需要考虑的成本，使用前请再三斟酌。（感觉没有多少使用的意义）



### 16.过期策略---拓展

Redis 所有的数据结构都可以设置过期时间，时间一到，就会自动删除。你可以想象Redis 内部有一个死神，时刻盯着所有设置了过期时间的 key，寿命一到就会立即收割。（有点秀）但是会不会因为要杀死的太多，使得死神忙不过来？

redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。除了定时遍历之外，它还会使用惰性策略来删除过期的 key，所谓惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除。定时删除是集中处理，惰性删除是零散处理。

所以业务开发人员一定要注意过期时间，如果有大批量的 key 过期，要给过期时间设置一个随机范围，而不能全部在同一时间过期。掌阅服务端在开发过程中就曾出现过多次因为大量 key 同时过期导致的卡顿报警现象，通过将过期时间随机化总是能很好地解决了这个问题，希望读者们今后能少犯这样的错误。

从库的过期策略：从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的key。所以会导致数据的不一致性。



### 17.LRU---拓展

当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)。这显然是我们不想看到的，这时我们必须处理redis中的数据。**简而言之就是如何删除key**

当实际内存超出 maxmemory 时，Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。我觉得以我们银行的资本，不太可能出现内存超出这一问题。

LRU算法：实现 LRU 算法除了需要 key/value 字典外，还需要附加一个链表，链表中的元素按照一定的顺序进行排列。当空间满的时候，会踢掉链表尾部的元素。当字典的某个元素被访问时，它在链表中的位置会被移动到表头。所以链表的元素排列顺序就是元素最近被访问的时间顺序。（这不就是操作系统中的LRU算法嘛）

注意，Redis 使用的是一种近似 LRU 算法，它跟 LRU 算法还不太一样。之所以不使用 LRU算法，是因为需要消耗大量的额外的内存，需要对现有的数据结构进行较大的改造。处理 key 过期方式分为集中处理和懒惰处理，LRU 淘汰不一样，它的处理方式只有懒惰处理。当 Redis 执行写操作时，发现内存超出 maxmemory，就会执行一次LRU 淘汰算法。这个算法也很简单，就是随机采样出 5(可以配置) 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于maxmemory 为止。



### 18.HyperLogLog---应用

思考这样一个问题，我们如何统计一个网站或者一个app的日访问量？

1. 可以给每个网页一个独立的 Redis 计数器，这个计数器的 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 用户访问量。但是这样计算出的访问量是不准确的，一个用户可以访问多次，真正的访问量是要去重的。
2. 于是我们想到可以为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了（因为set是去重的）。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的日访问量。但是如果访问量很大，那么set集合就会非常浪费空间。到底需不需要这么精确的统计呢？
3. HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不
   精确，标准误差是 0.81%，这样的精确度已经可以满足很多业务需求了。HyperLogLog 提供了两个指令 pfadd 和 pfcount，这两个指令就等同于set集合的sadd与scard。
4. HyperLogLog 这个数据结构不是免费的，不是说使用这个数据结构要花钱，它需要占据一定 12k 的存储空间，所以它不适合统计单个用户相关的数据。相比 set 存储方案，HyperLogLog 所使用的空间那真是可以使用千斤对比四两来形容了。
5. HyperLogLog 的使用非常简单，但是实现原理比较复杂，所以咋们先不了解，以后用到了再了解试试。



### 19.布隆过滤器---应用

HyperLogLog 数据结构来进行估数，它非常有价值，可以解决但是如果我们想知道某一个值是不是已经在 HyperLogLog 结构里面了，它就无能为力了，它只提供了 pfadd 和 pfcount 方法，没有提供 pfcontains 这种方法。很多精确度不高的统计需求。

布隆过滤器可以理解为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某个对象是否存在时，它可能会误判（跟HyperLogLog一样都不咋精确）。布隆过滤器就是专门用来解决去重问题的。它在起到去重的同时，在空间上还能节省 90% 以上，只是稍微有那么点不精确，也就是有一定的误判概率。（空间优化减少的同时，精确度也会减少，不能够两全）

当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。布隆过滤器有二个基本指令，bf.add 添加元素，bf.exists 查询元素是否存在，它的用法和 set 集合的 sadd 和 sismember 差不多。

布隆过滤器可不可以理解为一个占用空间较少，但是数据精确度较低的set结构实现。



### 20.简单限流---应用

系统要限定用户的某个行为在指定的时间里只能允许发生 N 次，如何使用Redis 的数据结构来实现这个限流的功能？(这个在我行的项目中是怎么实现的呢 ？)

```redis
# 记录行为
 pipe.zadd(key, now_ts, now_ts) # value 和 score 都使用毫秒时间戳
 # 移除时间窗口之前的行为记录，剩下的都是时间窗口内的
 pipe.zremrangebyscore(key, 0, now_ts - period * 1000)
 # 获取窗口内的行为数量
 pipe.zcard(key)
```

用一个 zset 结构记录用户的行为历史，每一个行为都会作为 zset 中的一个key 保存下来。同一个用户同一种行为用一个 zset 记录。



### 21.漏斗限流---应用





### 22.管道---原理

当我们使用客户端对 Redis 进行一次操作时，如下图所示，客户端将请求传送给服务器，服务器处理完毕后，再将响应回复给客户端。这要花费一个网络数据包来回的时间。回到客户端代码层面，客户端是经历了写-读-写-读四个操作才完整地执行了两条指令。**现在如果我们调整读写顺序，改成写—写-读-读，这两个指令同样可以正常完成。两个连续的写操作和两个连续的读操作总共只会花费一次网络来回，就好比连续的 write操作合并了，连续的 read 操作也合并了一样。**

这便是管道操作的本质，服务器根本没有任何区别对待，还是收到一条消息，执行一条消息，回复一条消息的正常的流程。客户端通过对管道中的指令列表改变读写顺序就可以大幅节省 IO 时间。管道中指令越多，效果越好。

**管道的本质是客户端通过改变了读写的顺序带来的性能的巨大提升。**



### 23.Redis事务

Redis 在形式上与别的数据库事务看起来也差不多，分别multi/exec/discard。multi 指示事务的开始，exec 指示事务的执行，discard 指示事务的丢弃。

```redis
> multi
OK
> incr books
QUEUED
> incr books
QUEUED
> exec
(integer) 1
(integer) 2
```

上面的指令演示了一个完整的事务过程，所有的指令在 exec 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 exec 指令，才开执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。因为 Redis 的单线程特性，它不用担心自己在执行队列的时候被其它指令打搅，可以保证他们能得到的「原子性」执行。事务的原子性是指要么事务全部成功，要么全部失败。

Redis 的事务根本不能算「原子性」，而仅仅是满足了事务的「隔离性」，隔离性中的串行化——当前执行的事务有着不被其它事务打断的权利。**就是redis事务如果中途执行不成功，不会影响后面的继续执行。**

所以通常 Redis 的客户端在执行事务时都会结合 pipeline(管道) 一起使用，这样可以将多次 IO 操作压缩为单次 IO 操作。

watch 会在事务开始之前盯住 1 个或多个关键变量，当事务执行时，也就是服务器收到了 exec 指令要顺序执行缓存的事务队列时，Redis 会检查关键变量自 watch 之后，是否被修改了 (包括当前事务所在的客户端)。如果关键变量被人动过了，exec 指令就会返回 null回复告知客户端事务执行失败，这个时候客户端一般会选择重试。Redis 禁止在 multi 和 exec 之间执行 watch 指令，而必须在 multi 之前做好盯住关键变量，否则会出错。

接下来我们使用 JAVA 语言来实现对余额的加倍操作。（使用乐观锁watch）

```java
public static void main(String[] args) {
 Jedis jedis = new Jedis();
 String userId = "abc";
 String key = keyFor(userId);
 jedis.setnx(key, String.valueOf(5)); //setnx 做初始化,将5转化成字符串
 System.out.println(doubleAccount(jedis, userId));
 jedis.close();
}
public static int doubleAccount(Jedis jedis, String userId) {
 String key = keyFor(userId); 
 while (true) {
 jedis.watch(key);  //检查key是否被修改了
 int value = Integer.parseInt(jedis.get(key));  //获得value并转化成int
 value *= 2; // 加倍
 Transaction tx = jedis.multi(); //事务开始
 tx.set(key, String.valueOf(value)); //重新设置value
 List<Object> res = tx.exec(); //事务结束
 if (res != null) {
 break; // 成功了
 }
 }
 return Integer.parseInt(jedis.get(key)); // 重新获取余额
}
//将userId转化成key值
public static String keyFor(String userId) {
   return String.format("account_{}", userId);
}
```



### 24.懒惰删除---拓展

删除指令 del 会直接释放对象的内存，大部分情况下，这个指令非常快，没有明显延迟。不过如果删除的 key 是一个非常大的对象，比如一个包含了千万元素的 hash，那么删除操作就会导致单线程卡顿。

Redis 为了解决这个卡顿问题，在 4.0 版本引入了 unlink 指令，它能对删除操作进行懒处理，丢给后台线程来异步回收内存。unlink key

一直以来我们认为 Redis 是单线程的，单线程为 Redis 带来了代码的简洁性和丰富多样的数据结构。不过 Redis 内部实际上并不是只有一个主线程，它还有几个异步线程专门用来处理一些耗时的操作。



### 25.保护 Redis---拓展

- 指令安全：Redis 有一些非常危险的指令，这些指令会对 Redis 的稳定以及数据安全造成非常严重的影响。比如 keys 指令会导致 Redis 卡顿，flushdb 和 flushall 会让 Redis 的所有数据全部清空。


- 端口安全：Redis 默认会监听 *:6379，如果当前的服务器主机有外网地址，Redis 的服务将会直接暴露在公网上，任何一个初级黑客使用适当的工具对 IP 地址进行端口扫描就可以探测出来。
- Lua 脚本安全：开发者必须禁止 Lua 脚本由用户输入的内容 (UGC) 生成，这可能会被黑客利用以植入恶意的攻击代码来得到 Redis 的主机权限。



### 26.Redis 安全通信---拓展

想象这样一个应用场景，公司有两个机房。因为一个紧急需求，需要跨机房读取 Redis数据。应用部署在 A 机房，存储部署在 B 机房。如果使用普通 tcp 直接访问，因为跨机房所以传输数据会暴露在公网，这非常不安全，客户端服务器交互的数据存在被窃听的风险。

Redis 本身并不支持 SSL 安全链接，不过有了 SSL 代理软件，我们可以让通信数据透明地得到加密，就好像 Redis 穿上了一层隐身外套一样。spiped 就是这样的一款 SSL 代理软件，它是 Redis 官方推荐的代理软件。



### 27.探索「字典」内部---底层

dict 是 Redis 服务器中出现最为频繁的复合型数据结构，dict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。所以，字典数据结构的精华就落在了 hashtable 结构上了。hashtable 的结构和 Java HashMap 几乎是一样的，都是通过分桶的方式解决 hash 冲突。第一维是数组，第二维是链表。数组中存储的是第二维链表的第一个元素的指针。

hashtable 的性能好不好完全取决于 hash 函数的质量。hash 函数如果可以将 key 打散的比较均匀，那么这个 hash 函数就是个好函数。

如果 hash 函数存在偏向性，黑客就可能利用这种偏向性对服务器进行攻击。存在偏向性的 hash 函数在特定模式下的输入会导致 hash 第二维链表长度极为不均匀，甚至所有的元素都集中到个别链表中，直接导致查找效率急剧下降，从 O(1)退化到 O(n)。有限的服务器计算能力将会被 hashtable 的查找效率彻底拖垮。这就是所谓 hash 攻击。

正常情况下，当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。



### 28.探索「压缩列表」内部---底层

Redis 为了节约内存空间使用，zset 和 hash 容器对象在元素个数较少的时候，采用**压缩列表** (ziplist) 进行存储。压缩列表是一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。

```redis
struct ziplist<T> {
 int32 zlbytes; // 整个压缩列表占用字节数
 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点
 int16 zllength; // 元素个数
 T[] entries; // 元素内容列表，挨个挨个紧凑存储
 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF
}

```

entry 块随着容纳的元素类型不同，也会有不一样的结构。

```redis
struct entry {
 int<var> prevlen; // 前一个 entry 的字节长度
 int<var> encoding; // 元素类型编码
 optional byte[] content; // 元素内容
}

```

压缩列表为了支持双向遍历，所以才会有 ztail_offset 这个字段，用来快速定位到最后一个元素，然后倒着遍历。而prevlen是当压缩列表倒着遍历时，需要通过这个字段来快速定位到下一个元素的位置。Redis 通过encoding这个字段的前缀位来识别具体存储的数据形式。注意到 content 字段在结构体中定义为 optional 类型，表示这个字段是可选的，对于很小的整数而言，它的内容已经内联到 encoding 字段的尾部了。

如果 ziplist 占据内存太大，重新分配内存和拷贝内存就会有很大的消耗。所以 ziplist不适合存储大型字符串，存储的元素也不宜过多。

当 set 集合容纳的元素都是整数并且元素个数较小时，Redis 会使用 intset（小整数集合） 来存储结合元素。intset 是紧凑的数组结构，同时支持 16 位、32 位和 64 位整数。

```redis
> sadd codehole 1 2 3
(integer) 3
> debug object codehole
Value at:0x7fec2dc2bde0 refcount:1 encoding:intset serializedlength:15 lru:6065795 lru_seconds_idle:4
> sadd codehole go java python
(integer) 3
> debug object codehole
Value at:0x7fec2dc2bde0 refcount:1 encoding:hashtable serializedlength:22 lru:6065810 lru_seconds_idle:5
```

**使用debug object key可以查看这个key具体的存储类型。**



### 29.探索「快速列表」内部---底层

Redis 早期版本存储 list 列表数据结构使用的是压缩列表 ziplist 和普通的双向链表linkedlist，也就是元素少时用 ziplist，元素多时用 linkedlist。考虑到链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。后续版本对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist。

quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。一个ziplist就是一个quicklist的节点！

**反正只需要知道list数据在现在是用quicklist进行存储的。**



### 30.探索「跳跃列表」内部结构---底层

Redis 的 zset 是一个复合结构，一方面它需要一个 hash 结构来存储 value 和 score 的对应关系，另一方面需要提供按照 score 来排序的功能，还需要能够指定 score 的范围来获取 value 列表的功能，这就需要另外一个结构「跳跃列表」。



### 31.对五种基本数据类型的总结---底层

Redis 所有的数据结构都是以唯一的 key字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。**不同类型的数据结构的差异就在于 value 的结构不一样。**

Redis用的五大数据类型来表示键和值，每次在Redis数据库中创建一个键值对时，至少会创建两个对象，一个是键对象，一个是值对象，键都是string类型的，而value是五种类型之一。Redis中的每个对象都是由 redisObject 结构来表示：

```java
typedef struct redisObject{
     //类型，五大类型
     unsigned type:4;
     //编码
     unsigned encoding:4;
     //指向底层数据结构的指针，例如String就是指向SDS
     void *ptr;
     //引用计数
     int refcount;
     //记录最后一次被程序访问的时间
     unsigned lru:22;
}robj
```

- String: Redis 中的字符串是可以修改的字符串，在内存中它是以字节数组的形式存在的。Redis 的字符串有两种存储方式，在长度特别短时，使用 emb 形式存储 (embeded)，当长度超过 44 时，使用 raw 形式存储。![](D:\图片\String存储.png)


- list：list数据在现在是用quicklist进行存储的。quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。一个ziplist就是一个quicklist的节点！

- hash：哈希对象的编码可以是 ziplist 或者 hashtable。当元素较少时，采用压缩列表，和上面列表对象使用 ziplist 编码一样，当同时满足下面两个条件时，使用ziplist（压缩列表）编码：

  　　1、列表保存元素个数小于512个

  　　2、每个元素长度小于64字节

  不能满足这两个条件的时候使用 hashtable 编码。第一个条件可以通过配置文件中的 set-max-intset-entries 进行修改。

  ![](D:\图片\hash存储.png)


- set：集合对象的编码可以是 intset 或者 hashtable。intset 编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合中。

  hashtable 编码的集合对象使用 字典作为底层实现，字典的每个键都是一个字符串对象，这里的每个字符串对象就是一个集合中的元素，而字典的值则全部设置为 null。这里可以类比Java集合中HashSet 集合的实现，HashSet 集合是由 HashMap 来实现的，集合中的元素就是 HashMap 的key，而 HashMap 的值都设为 null。

  当集合同时满足以下两个条件时，使用 intset 编码：

  　　1、集合对象中所有元素都是整数

  　　2、集合对象所有元素数量不超过512

  不能满足这两个条件的就使用 hashtable 编码。第二个条件可以通过配置文件的 set-max-intset-entries 进行配置。

  ![](D:\图片\set存储.png)


- zset: 有序集合的编码可以是 ziplist 或者 skiplist。ziplist 编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。并且压缩列表内的集合元素按分值从小到大的顺序进行排列，小的放置在靠近表头的位置，大的放置在靠近表尾的位置。

  ![](D:\图片\zset.png)